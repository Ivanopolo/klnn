{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "\n",
    "from kfkd import load2d, makeSubmit\n",
    "from utils import iterate_minibatches\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading data...\")\n",
    "\n",
    "#Attention! Not all data is being loaded, only the rows without N/A vals.\n",
    "X, y = load2d()\n",
    "X_train = X[:1900]\n",
    "y_train = y[:1900]\n",
    "X_test = X[1900:]\n",
    "y_test = y[1900:]\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model and compiling functions...\n",
      "Starting training...\n",
      "Epoch 1 of 100 took 0.603s\n",
      "  training loss:\t\t0.058388\n",
      "  validation loss:\t\t0.007349\n",
      "Epoch 2 of 100 took 0.571s\n",
      "  training loss:\t\t0.025784\n",
      "  validation loss:\t\t0.006679\n",
      "Epoch 3 of 100 took 0.574s\n",
      "  training loss:\t\t0.009203\n",
      "  validation loss:\t\t0.005314\n",
      "Epoch 4 of 100 took 0.578s\n",
      "  training loss:\t\t0.006993\n",
      "  validation loss:\t\t0.004865\n",
      "Epoch 5 of 100 took 0.569s\n",
      "  training loss:\t\t0.006460\n",
      "  validation loss:\t\t0.004730\n",
      "Epoch 6 of 100 took 0.564s\n",
      "  training loss:\t\t0.006242\n",
      "  validation loss:\t\t0.004900\n",
      "Epoch 7 of 100 took 0.562s\n",
      "  training loss:\t\t0.005932\n",
      "  validation loss:\t\t0.004779\n",
      "Epoch 8 of 100 took 0.562s\n",
      "  training loss:\t\t0.005769\n",
      "  validation loss:\t\t0.004778\n",
      "Epoch 9 of 100 took 0.569s\n",
      "  training loss:\t\t0.005603\n",
      "  validation loss:\t\t0.004750\n",
      "Epoch 10 of 100 took 0.566s\n",
      "  training loss:\t\t0.005521\n",
      "  validation loss:\t\t0.004777\n",
      "Epoch 11 of 100 took 0.563s\n",
      "  training loss:\t\t0.005382\n",
      "  validation loss:\t\t0.004763\n",
      "Epoch 12 of 100 took 0.562s\n",
      "  training loss:\t\t0.005296\n",
      "  validation loss:\t\t0.004724\n",
      "Epoch 13 of 100 took 0.562s\n",
      "  training loss:\t\t0.005187\n",
      "  validation loss:\t\t0.004736\n",
      "Epoch 14 of 100 took 0.568s\n",
      "  training loss:\t\t0.005136\n",
      "  validation loss:\t\t0.004740\n",
      "Epoch 15 of 100 took 0.569s\n",
      "  training loss:\t\t0.004988\n",
      "  validation loss:\t\t0.004694\n",
      "Epoch 16 of 100 took 0.570s\n",
      "  training loss:\t\t0.004997\n",
      "  validation loss:\t\t0.004708\n",
      "Epoch 17 of 100 took 0.567s\n",
      "  training loss:\t\t0.004971\n",
      "  validation loss:\t\t0.004705\n",
      "Epoch 18 of 100 took 0.567s\n",
      "  training loss:\t\t0.004866\n",
      "  validation loss:\t\t0.004723\n",
      "Epoch 19 of 100 took 0.566s\n",
      "  training loss:\t\t0.004768\n",
      "  validation loss:\t\t0.004709\n",
      "Epoch 20 of 100 took 0.566s\n",
      "  training loss:\t\t0.004753\n",
      "  validation loss:\t\t0.004678\n",
      "Epoch 21 of 100 took 0.573s\n",
      "  training loss:\t\t0.004720\n",
      "  validation loss:\t\t0.004690\n",
      "Epoch 22 of 100 took 0.568s\n",
      "  training loss:\t\t0.004729\n",
      "  validation loss:\t\t0.004687\n",
      "Epoch 23 of 100 took 0.564s\n",
      "  training loss:\t\t0.004637\n",
      "  validation loss:\t\t0.004679\n",
      "Epoch 24 of 100 took 0.562s\n",
      "  training loss:\t\t0.004643\n",
      "  validation loss:\t\t0.004673\n",
      "Epoch 25 of 100 took 0.568s\n",
      "  training loss:\t\t0.004599\n",
      "  validation loss:\t\t0.004668\n",
      "Epoch 26 of 100 took 0.564s\n",
      "  training loss:\t\t0.004598\n",
      "  validation loss:\t\t0.004679\n",
      "Epoch 27 of 100 took 0.576s\n",
      "  training loss:\t\t0.004562\n",
      "  validation loss:\t\t0.004674\n",
      "Epoch 28 of 100 took 0.570s\n",
      "  training loss:\t\t0.004584\n",
      "  validation loss:\t\t0.004677\n",
      "Epoch 29 of 100 took 0.569s\n",
      "  training loss:\t\t0.004535\n",
      "  validation loss:\t\t0.004669\n",
      "Epoch 30 of 100 took 0.575s\n",
      "  training loss:\t\t0.004545\n",
      "  validation loss:\t\t0.004662\n",
      "Epoch 31 of 100 took 0.573s\n",
      "  training loss:\t\t0.004509\n",
      "  validation loss:\t\t0.004661\n",
      "Epoch 32 of 100 took 0.575s\n",
      "  training loss:\t\t0.004504\n",
      "  validation loss:\t\t0.004657\n",
      "Epoch 33 of 100 took 0.564s\n",
      "  training loss:\t\t0.004509\n",
      "  validation loss:\t\t0.004665\n",
      "Epoch 34 of 100 took 0.566s\n",
      "  training loss:\t\t0.004490\n",
      "  validation loss:\t\t0.004659\n",
      "Epoch 35 of 100 took 0.566s\n",
      "  training loss:\t\t0.004472\n",
      "  validation loss:\t\t0.004647\n",
      "Epoch 36 of 100 took 0.567s\n",
      "  training loss:\t\t0.004457\n",
      "  validation loss:\t\t0.004655\n",
      "Epoch 37 of 100 took 0.565s\n",
      "  training loss:\t\t0.004437\n",
      "  validation loss:\t\t0.004646\n",
      "Epoch 38 of 100 took 0.562s\n",
      "  training loss:\t\t0.004399\n",
      "  validation loss:\t\t0.004649\n",
      "Epoch 39 of 100 took 0.563s\n",
      "  training loss:\t\t0.004426\n",
      "  validation loss:\t\t0.004652\n",
      "Epoch 40 of 100 took 0.564s\n",
      "  training loss:\t\t0.004422\n",
      "  validation loss:\t\t0.004651\n",
      "Epoch 41 of 100 took 0.566s\n",
      "  training loss:\t\t0.004394\n",
      "  validation loss:\t\t0.004643\n",
      "Epoch 42 of 100 took 0.563s\n",
      "  training loss:\t\t0.004417\n",
      "  validation loss:\t\t0.004653\n",
      "Epoch 43 of 100 took 0.563s\n",
      "  training loss:\t\t0.004414\n",
      "  validation loss:\t\t0.004639\n",
      "Epoch 44 of 100 took 0.566s\n",
      "  training loss:\t\t0.004447\n",
      "  validation loss:\t\t0.004646\n",
      "Epoch 45 of 100 took 0.564s\n",
      "  training loss:\t\t0.004416\n",
      "  validation loss:\t\t0.004653\n",
      "Epoch 46 of 100 took 0.563s\n",
      "  training loss:\t\t0.004415\n",
      "  validation loss:\t\t0.004645\n",
      "Epoch 47 of 100 took 0.564s\n",
      "  training loss:\t\t0.004417\n",
      "  validation loss:\t\t0.004644\n",
      "Epoch 48 of 100 took 0.564s\n",
      "  training loss:\t\t0.004397\n",
      "  validation loss:\t\t0.004631\n",
      "Epoch 49 of 100 took 0.562s\n",
      "  training loss:\t\t0.004430\n",
      "  validation loss:\t\t0.004635\n",
      "Epoch 50 of 100 took 0.566s\n",
      "  training loss:\t\t0.004368\n",
      "  validation loss:\t\t0.004639\n",
      "Epoch 51 of 100 took 0.573s\n",
      "  training loss:\t\t0.004442\n",
      "  validation loss:\t\t0.004641\n",
      "Epoch 52 of 100 took 0.566s\n",
      "  training loss:\t\t0.004388\n",
      "  validation loss:\t\t0.004636\n",
      "Epoch 53 of 100 took 0.565s\n",
      "  training loss:\t\t0.004363\n",
      "  validation loss:\t\t0.004631\n",
      "Epoch 54 of 100 took 0.565s\n",
      "  training loss:\t\t0.004408\n",
      "  validation loss:\t\t0.004631\n",
      "Epoch 55 of 100 took 0.563s\n",
      "  training loss:\t\t0.004419\n",
      "  validation loss:\t\t0.004642\n",
      "Epoch 56 of 100 took 0.565s\n",
      "  training loss:\t\t0.004372\n",
      "  validation loss:\t\t0.004634\n",
      "Epoch 57 of 100 took 0.564s\n",
      "  training loss:\t\t0.004374\n",
      "  validation loss:\t\t0.004636\n",
      "Epoch 58 of 100 took 0.563s\n",
      "  training loss:\t\t0.004358\n",
      "  validation loss:\t\t0.004629\n",
      "Epoch 59 of 100 took 0.566s\n",
      "  training loss:\t\t0.004412\n",
      "  validation loss:\t\t0.004632\n",
      "Epoch 60 of 100 took 0.563s\n",
      "  training loss:\t\t0.004366\n",
      "  validation loss:\t\t0.004624\n",
      "Epoch 61 of 100 took 0.565s\n",
      "  training loss:\t\t0.004387\n",
      "  validation loss:\t\t0.004620\n",
      "Epoch 62 of 100 took 0.563s\n",
      "  training loss:\t\t0.004375\n",
      "  validation loss:\t\t0.004632\n",
      "Epoch 63 of 100 took 0.563s\n",
      "  training loss:\t\t0.004377\n",
      "  validation loss:\t\t0.004626\n",
      "Epoch 64 of 100 took 0.565s\n",
      "  training loss:\t\t0.004355\n",
      "  validation loss:\t\t0.004620\n",
      "Epoch 65 of 100 took 0.563s\n",
      "  training loss:\t\t0.004364\n",
      "  validation loss:\t\t0.004636\n",
      "Epoch 66 of 100 took 0.563s\n",
      "  training loss:\t\t0.004349\n",
      "  validation loss:\t\t0.004616\n",
      "Epoch 67 of 100 took 0.562s\n",
      "  training loss:\t\t0.004397\n",
      "  validation loss:\t\t0.004628\n",
      "Epoch 68 of 100 took 0.562s\n",
      "  training loss:\t\t0.004371\n",
      "  validation loss:\t\t0.004624\n",
      "Epoch 69 of 100 took 0.562s\n",
      "  training loss:\t\t0.004375\n",
      "  validation loss:\t\t0.004628\n",
      "Epoch 70 of 100 took 0.562s\n",
      "  training loss:\t\t0.004360\n",
      "  validation loss:\t\t0.004624\n",
      "Epoch 71 of 100 took 0.563s\n",
      "  training loss:\t\t0.004387\n",
      "  validation loss:\t\t0.004628\n",
      "Epoch 72 of 100 took 0.562s\n",
      "  training loss:\t\t0.004368\n",
      "  validation loss:\t\t0.004612\n",
      "Epoch 73 of 100 took 0.563s\n",
      "  training loss:\t\t0.004378\n",
      "  validation loss:\t\t0.004623\n",
      "Epoch 74 of 100 took 0.562s\n",
      "  training loss:\t\t0.004378\n",
      "  validation loss:\t\t0.004622\n",
      "Epoch 75 of 100 took 0.562s\n",
      "  training loss:\t\t0.004382\n",
      "  validation loss:\t\t0.004616\n",
      "Epoch 76 of 100 took 0.562s\n",
      "  training loss:\t\t0.004347\n",
      "  validation loss:\t\t0.004623\n",
      "Epoch 77 of 100 took 0.563s\n",
      "  training loss:\t\t0.004382\n",
      "  validation loss:\t\t0.004610\n",
      "Epoch 78 of 100 took 0.565s\n",
      "  training loss:\t\t0.004335\n",
      "  validation loss:\t\t0.004614\n",
      "Epoch 79 of 100 took 0.563s\n",
      "  training loss:\t\t0.004397\n",
      "  validation loss:\t\t0.004608\n",
      "Epoch 80 of 100 took 0.566s\n",
      "  training loss:\t\t0.004350\n",
      "  validation loss:\t\t0.004613\n",
      "Epoch 81 of 100 took 0.563s\n",
      "  training loss:\t\t0.004359\n",
      "  validation loss:\t\t0.004609\n",
      "Epoch 82 of 100 took 0.562s\n",
      "  training loss:\t\t0.004385\n",
      "  validation loss:\t\t0.004611\n",
      "Epoch 83 of 100 took 0.562s\n",
      "  training loss:\t\t0.004325\n",
      "  validation loss:\t\t0.004610\n",
      "Epoch 84 of 100 took 0.562s\n",
      "  training loss:\t\t0.004356\n",
      "  validation loss:\t\t0.004605\n",
      "Epoch 85 of 100 took 0.565s\n",
      "  training loss:\t\t0.004381\n",
      "  validation loss:\t\t0.004606\n",
      "Epoch 86 of 100 took 0.564s\n",
      "  training loss:\t\t0.004318\n",
      "  validation loss:\t\t0.004616\n",
      "Epoch 87 of 100 took 0.566s\n",
      "  training loss:\t\t0.004343\n",
      "  validation loss:\t\t0.004605\n",
      "Epoch 88 of 100 took 0.564s\n",
      "  training loss:\t\t0.004360\n",
      "  validation loss:\t\t0.004599\n",
      "Epoch 89 of 100 took 0.563s\n",
      "  training loss:\t\t0.004339\n",
      "  validation loss:\t\t0.004601\n",
      "Epoch 90 of 100 took 0.563s\n",
      "  training loss:\t\t0.004361\n",
      "  validation loss:\t\t0.004594\n",
      "Epoch 91 of 100 took 0.565s\n",
      "  training loss:\t\t0.004335\n",
      "  validation loss:\t\t0.004594\n",
      "Epoch 92 of 100 took 0.566s\n",
      "  training loss:\t\t0.004311\n",
      "  validation loss:\t\t0.004589\n",
      "Epoch 93 of 100 took 0.564s\n",
      "  training loss:\t\t0.004382\n",
      "  validation loss:\t\t0.004587\n",
      "Epoch 94 of 100 took 0.567s\n",
      "  training loss:\t\t0.004355\n",
      "  validation loss:\t\t0.004582\n",
      "Epoch 95 of 100 took 0.563s\n",
      "  training loss:\t\t0.004335\n",
      "  validation loss:\t\t0.004587\n",
      "Epoch 96 of 100 took 0.564s\n",
      "  training loss:\t\t0.004357\n",
      "  validation loss:\t\t0.004592\n",
      "Epoch 97 of 100 took 0.566s\n",
      "  training loss:\t\t0.004362\n",
      "  validation loss:\t\t0.004580\n",
      "Epoch 98 of 100 took 0.564s\n",
      "  training loss:\t\t0.004369\n",
      "  validation loss:\t\t0.004571\n",
      "Epoch 99 of 100 took 0.565s\n",
      "  training loss:\t\t0.004271\n",
      "  validation loss:\t\t0.004572\n",
      "Epoch 100 of 100 took 0.562s\n",
      "  training loss:\t\t0.004341\n",
      "  validation loss:\t\t0.004569\n"
     ]
    }
   ],
   "source": [
    "def build_cnn(input_var=None):\n",
    "\n",
    "    # Input layer:\n",
    "    network = lasagne.layers.InputLayer(shape=(None, 1, 96, 96),\n",
    "                                        input_var=input_var)\n",
    "    \n",
    "    # Convolutional layer with 32 kernels of size 5x5. Strided and padded\n",
    "    # convolutions are supported as well; see the docstring.\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, num_filters=16, filter_size=(5, 5),\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "\n",
    "    # Max-pooling layer of factor 2 in both dimensions:\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "\n",
    "    # Another convolution with 32 5x5 kernels, and another 2x2 pooling:\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, num_filters=16, filter_size=(5, 5),\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "\n",
    "    # A fully-connected layer of 256 units with 50% dropout on its inputs:\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(network, p=0.5),\n",
    "            num_units=256,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    # And, finally, the 10-unit output layer with 50% dropout on its inputs:\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(network, p=0.5),\n",
    "            num_units=30,\n",
    "            nonlinearity=None)\n",
    "\n",
    "    return network\n",
    "\n",
    "num_epochs=100\n",
    "\n",
    "# Prepare Theano variables for inputs and targets\n",
    "input_var = T.tensor4('inputs')\n",
    "target_var = T.dmatrix('targets')\n",
    "\n",
    "# Create neural network model (depending on first command line parameter)\n",
    "print(\"Building model and compiling functions...\")\n",
    "network = build_cnn(input_var)\n",
    "\n",
    "# Create a loss expression for training, i.e., a scalar objective we want\n",
    "# to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.squared_error(prediction, target_var)\n",
    "loss = loss.mean()\n",
    "# We could add some weight decay as well here, see lasagne.regularization.\n",
    "\n",
    "# Create update expressions for training, i.e., how to modify the\n",
    "# parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "# Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(\n",
    "        loss, params, learning_rate=0.1, momentum=0.9)\n",
    "\n",
    "# Create a loss expression for validation/testing. The crucial difference\n",
    "# here is that we do a deterministic forward pass through the network,\n",
    "# disabling dropout layers.\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "test_loss = lasagne.objectives.squared_error(test_prediction, target_var)\n",
    "test_loss = test_loss.mean()\n",
    "\n",
    "# Compile a function performing a training step on a mini-batch (by giving\n",
    "# the updates dictionary) and returning the corresponding training loss:\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "# Compile a second function computing the validation loss and accuracy:\n",
    "val_fn = theano.function([input_var, target_var], [test_loss])\n",
    "\n",
    "# Compile function for prediction for test dataset\n",
    "test_fn = theano.function([input_var], [test_prediction])\n",
    "\n",
    "# Finally, launch the training loop.\n",
    "print(\"Starting training...\")\n",
    "# We iterate over epochs:\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, y_train, 128, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        train_err += train_fn(inputs, targets)\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_err = val_fn(X_test, y_test)[0]\n",
    "\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load data for for submission\n",
    "X_submit, _ = load2d(test=True)\n",
    "\n",
    "#Make predictions with trained network\n",
    "preds = test_fn(X_submit)[0]\n",
    "\n",
    "#Create ./submission.csv that you should upload to Kaggle.com to get leaderboard results\n",
    "makeSubmit(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
